# r1_workflows.yaml
# O-RAN R1 Multi-Step Workflow Templates (R1AP v08.00 Compliant)
# =========================================================================
#
# Reference: O-RAN.WG2.TS.R1AP-R004-v08.00
#
# This file defines detailed workflow templates using R1AP-compliant
# terminology and API paths. All workflows use ONLY R1 interface APIs.
#
# R1AP v08.00 Key Terminology:
#   - dmeTypeId: String identifier for DME type
#     Format: "namespace:name:version" (e.g., "oran:coverage-kpis:1.0.0")
#     Note: Case-sensitive, typically lowercase namespace
#   - dataJobId: Data job identifier
#   - DataJobInfo: Schema for data job creation (Table 7.3.8.1.2-1)
#   - dataDeliveryMode: CONTINUOUS | ONE_TIME
#   - dataDeliveryMethod: PUSH_HTTP | PULL_HTTP | STREAMING_KAFKA
#
# Bootstrap API (R1AP v08.00 Section 6.4):
#   - Returns BootstrapInformation with apiEndpoints array
#   - Each entry is ApiEndpointInformation with apiName, apiEndPoint, tokenEndPoint
#
# Data Management APIs (R1AP v08.00 Section 7):
#   - Data Discovery: /data-discovery/v2/dme-types (v2.0.0)
#   - Data Access: /data-access/v2/data-jobs (v2.0.0-alpha.2)
#   - Data Registration: /data-registration/v2/production-capabilities (v2.0.0-alpha.2)
#   - Data Offer: /data-offer/v1/offers (v1.0.0)
#   - HTTP Push/Pull Data: /http-push-data/v1, /http-pull-data/v1 (v1.0.0)
#
# Service Management APIs (R1AP v08.00 Section 6.1-6.3):
#   - Service Registration: /published-apis/v1/ (v1.2.0)
#   - Service Discovery: /service-apis/v1/ (v1.2.0)
#   - Service Events: /capif-events/v1/ (v1.2.0)
#
# PUSH_HTTP Data Delivery:
#   - R1AP does NOT define OpenAPI for HTTP-based Push data delivery
#   - Payload format is IMPLEMENTATION-SPECIFIC (defined by dataDeliverySchemaId)
#   - Wire format is NOT standardized by R1AP
#
# DataAvailabilityNotification (separate mechanism):
#   - Posted to dataAvailabilityNotificationUri with 204 No Content response
#   - Different from actual data push
#
# R1 API Categories Included:
#   - Data Discovery: /data-discovery/v2/dme-types
#   - Data Access: /data-access/v2/data-jobs
#   - A1 Policy: /a1-policy-management/v1/policies
#   - AI/ML: /r1-aiml/v1/mlModels
#   - rApp Management: /r1-rapp-management/v1/rapps
#   - Fault Management: /ProvMnS/v1/{LDN}/AlarmList
#   - Config Schema: /ran-oam-cm-schema-info/v1/schemas
#
# NOT INCLUDED (separate interfaces):
#   - O1 APIs (direct O1 FCAPS)
#   - O2 APIs (o2_infrastructure_management, o2_deployment_management)
# =========================================================================

metadata:
  version: "3.0.0"
  description: "R1AP v08.00 compliant workflow templates for training dataset generation"
  spec_reference: "O-RAN.WG2.TS.R1AP-R004-v08.00"
  workflow_count: 10

# ============================================================
# DATA MANAGEMENT WORKFLOWS
# ============================================================
workflows:
  # -----------------------------------------------------------
  # Coverage Monitoring Setup (R1AP-Compliant)
  # -----------------------------------------------------------
  coverage_monitoring_setup:
    id: "wf_001"
    name: "Coverage Monitoring Setup"
    description: "Set up real-time monitoring for cell coverage KPIs using R1 Data Management"
    category: "data_management"
    complexity: "medium"
    step_count: 4
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Set up real-time monitoring for cell {cellId} to detect coverage degradation"
      - "Monitor RSRP and SINR for cell {cellId}"
      - "I need to track coverage KPIs for {cellId}"
      - "Create a coverage monitoring subscription for cell {cellId}"
      - "Watch coverage metrics for {cellId} and alert on issues"
      - "Set up RF quality monitoring for my cell"

    context_parameters:
      cellId:
        type: "string"
        examples: ["NRCell-100", "NRCell-200", "cell-001"]
      reportingPeriod:
        type: "integer"
        default: 60
        examples: [60, 300, 900]
      kpis:
        type: "array"
        default: ["rsrp_dbm", "rsrq_db", "sinr_db"]

    steps:
      # Step 1: Bootstrap - ALWAYS the first step (R1AP v08.00 Section 6.4)
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: |
          Agent only knows api_root and bootstrap path at startup. Must call bootstrap first
          to discover all other service endpoints. R1AP v08.00 returns apiEndpoints array
          containing ApiEndpointInformation for each available API.
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          # R1AP v08.00 returns apiEndpoints array with ApiEndpointInformation entries
          apiEndpoints:
            - apiName: "data-discovery"
              apiEndPoint:
                ipv4Addr: "smo.example.com"
                port: 443
              uri: "/data-discovery/v2"
            - apiName: "data-access"
              apiEndPoint:
                ipv4Addr: "smo.example.com"
                port: 443
              uri: "/data-access/v2"
            - apiName: "a1-policy-management"
              apiEndPoint:
                ipv4Addr: "smo.example.com"
                port: 443
              uri: "/a1-policy-management/v1"
          # For backward compatibility, also extract simplified paths
          serviceEndpoints:
            dataDiscovery: "/data-discovery/v2"
            dataAccess: "/data-access/v2"
            a1PolicyManagement: "/a1-policy-management/v1"

      # Step 2: Discover DME types
      - step: 2
        api: "data_discovery.GET_dme_types"
        uri: "${api_root}${step_1.serviceEndpoints.dataDiscovery}/dme-types"
        method: "GET"
        purpose: "Discover available DME types for coverage monitoring"
        reasoning: |
          Query the DME types catalog to find types that provide coverage KPIs.
          Look for DME types containing RSRP, RSRQ, or SINR measurements.
          The dmeTypeId format is "<namespace>:<name>:<version>" - we need to
          parse the response and select the appropriate type based on our needs.
        inputs:
          dataDiscoveryEndpoint: "FROM step_1.serviceEndpoints.dataDiscovery"
        selection_logic: |
          From the returned array of DME types, select one where:
          - dmeTypeDefinition.description mentions "coverage" or "RF quality"
          - OR supportedMeasurements includes rsrp_dbm, rsrq_db, or sinr_db
          Store the selected dmeTypeId and dataDeliverySchemaId for next step.
        expected_outputs:
          dmeTypeId: "DISCOVERED - e.g., oran:coverage-kpis:1.0.0"
          dataDeliverySchemaId: "DISCOVERED - from response"
          supportedDeliveryMethods: "DISCOVERED - e.g., [PUSH_HTTP, STREAMING_KAFKA]"

      # Step 3: Create data job
      - step: 3
        api: "data_access.POST_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs"
        method: "POST"
        purpose: "Create continuous data job for coverage KPIs"
        reasoning: |
          Using the discovered dmeTypeId and dataDeliverySchemaId from step 2,
          create a data job to stream coverage metrics. Use R1TD v04.01 compliant
          dataJobDefinition with dataSelector, targetSelector, and timing.
          Choose PUSH_HTTP if supported, configure the callback URI.
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dmeTypeId: "FROM step_2.dmeTypeId"
          dataDeliverySchemaId: "FROM step_2.dataDeliverySchemaId"
          cellId: "FROM context.cellId"
          measurementTypes: "FROM context.kpis"
          reportingPeriod: "FROM context.reportingPeriod"
        # R1TD v04.01 compliant request body structure
        request_body:
          # Use discovered dmeTypeId from step 2 (format: namespace:name:version)
          dmeTypeId: "${step_2.dmeTypeId}"
          # Data production schema per R1TD v04.01 Section 5.1.4.2
          dataJobDefinition:
            # DataSelector (R1TD Table 5.2.2.3.1.1-1)
            dataSelector:
              managementData:
                mgtDataName: "${context.kpis}"
            # TargetSelector (R1TD Table 5.2.2.3.1.2-1)
            targetSelector:
              objectInstances:
                - "/ManagedElement=gNB-001/GNBDUFunction=1/NRCellDU=${context.cellId}"
            # Timing (R1TD Table 5.2.2.3.1.3-1)
            timing:
              collectionWindow:
                startTime: "00:00:00"
              granularityPeriod: 900
              reportingPeriod: "${context.reportingPeriod}"
          dataDeliveryMode: "CONTINUOUS"
          dataDeliveryMethod: "PUSH_HTTP"
          # Use discovered dataDeliverySchemaId from step 2
          dataDeliverySchemaId: "${step_2.dataDeliverySchemaId}"
          pushDeliveryDetailsHttp:
            dataPushUri: "https://rapp.operator.com/callbacks/coverage-monitoring"
        expected_outputs:
          dataJobId: "RETURNED - job identifier"
          status: "ENABLED"

    cleanup:
      - step: 4
        api: "data_access.DELETE_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs/${step_3.dataJobId}"
        method: "DELETE"
        purpose: "Remove data job when monitoring is complete"
        reasoning: "Clean up the data job subscription when monitoring is no longer needed"
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dataJobId: "FROM step_3.dataJobId"
        trigger: "When monitoring objective achieved or cancelled"

    expected_outcome: "Continuous monitoring of coverage KPIs (RSRP, RSRQ, SINR) via PUSH_HTTP delivery to rApp callback."

    # PUSH_HTTP Data Delivery:
    # - R1AP does NOT define OpenAPI for HTTP-based Push data delivery
    # - Payload format is IMPLEMENTATION-SPECIFIC (defined by dataDeliverySchemaId)
    # - Example below is illustrative, actual format depends on implementation
    data_delivery_format:
      uri: "https://rapp.operator.com/callbacks/coverage-monitoring"
      description: "Payload format is IMPLEMENTATION-SPECIFIC (not R1AP-standardized)"
      payload_example:
        # Example only - actual format defined by dataDeliverySchemaId implementation
        cellId: "NRCell-100"
        rsrp_dbm: -95
        rsrq_db: -12
        sinr_db: 8

    kpis_involved: ["rsrp_dbm", "rsrq_db", "sinr_db"]
    related_workflows: ["capacity_monitoring_setup", "historical_data_request"]

  # -----------------------------------------------------------
  # Capacity Monitoring Setup (R1AP-Compliant)
  # -----------------------------------------------------------
  capacity_monitoring_setup:
    id: "wf_002"
    name: "Capacity Monitoring Setup"
    description: "Set up real-time monitoring for cell capacity and load using R1 Data Management"
    category: "data_management"
    complexity: "medium"
    step_count: 4
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Monitor PRB utilization for cell {cellId}"
      - "Set up capacity monitoring for {cellId}"
      - "Track load metrics for my cell"
      - "I want to watch throughput and PRB usage"
      - "Alert me when {cellId} is getting congested"

    context_parameters:
      cellId:
        type: "string"
        examples: ["NRCell-100", "NRCell-200"]
      prbThreshold:
        type: "integer"
        default: 85
        examples: [70, 80, 85, 90]
      reportingPeriod:
        type: "integer"
        default: 60

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover dataDiscovery and dataAccess endpoints."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            dataDiscovery: "/data-discovery/v2"
            dataAccess: "/data-access/v2"

      # Step 2: Discover DME types
      - step: 2
        api: "data_discovery.GET_dme_types"
        uri: "${api_root}${step_1.serviceEndpoints.dataDiscovery}/dme-types"
        method: "GET"
        purpose: "Discover available capacity DME types"
        reasoning: |
          Query the DME types catalog to find types that provide capacity KPIs.
          Look for DME types containing PRB utilization, active UEs, or throughput measurements.
        inputs:
          dataDiscoveryEndpoint: "FROM step_1.serviceEndpoints.dataDiscovery"
        selection_logic: |
          From the returned array of DME types, select one where:
          - dmeTypeDefinition.description mentions "capacity" or "load"
          - OR supportedMeasurements includes prb_utilization_dl_pct, active_ues, or throughput_dl_mbps_avg
        expected_outputs:
          dmeTypeId: "DISCOVERED - e.g., oran:capacity-kpis:1.0.0"
          dataDeliverySchemaId: "DISCOVERED - from response"
          supportedDeliveryMethods: "DISCOVERED - e.g., [PUSH_HTTP, STREAMING_KAFKA]"

      # Step 3: Create data job
      - step: 3
        api: "data_access.POST_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs"
        method: "POST"
        purpose: "Create continuous data job for capacity KPIs"
        reasoning: |
          Using the discovered dmeTypeId and dataDeliverySchemaId from step 2,
          create a data job to stream capacity metrics. Configure PUSH_HTTP delivery
          to our callback endpoint.
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dmeTypeId: "FROM step_2.dmeTypeId"
          dataDeliverySchemaId: "FROM step_2.dataDeliverySchemaId"
          cellId: "FROM context.cellId"
          reportingPeriod: "FROM context.reportingPeriod"
        # R1TD v04.01 compliant request body structure
        request_body:
          # Use discovered dmeTypeId from step 2 (format: namespace:name:version)
          dmeTypeId: "${step_2.dmeTypeId}"
          # Data production schema per R1TD v04.01 Section 5.1.4.2
          dataJobDefinition:
            # DataSelector (R1TD Table 5.2.2.3.1.1-1)
            dataSelector:
              managementData:
                mgtDataName:
                  - "RRU.PrbUsedDl"
                  - "RRU.PrbUsedUl"
                  - "RRC.ConnEstabSucc"
                  - "DRB.UEThpDl"
            # TargetSelector (R1TD Table 5.2.2.3.1.2-1)
            targetSelector:
              objectInstances:
                - "/ManagedElement=gNB-001/GNBDUFunction=1/NRCellDU=${context.cellId}"
            # Timing (R1TD Table 5.2.2.3.1.3-1)
            timing:
              collectionWindow:
                startTime: "00:00:00"
              granularityPeriod: 900
              reportingPeriod: "${context.reportingPeriod}"
          dataDeliveryMode: "CONTINUOUS"
          dataDeliveryMethod: "PUSH_HTTP"
          # Use discovered dataDeliverySchemaId from step 2
          dataDeliverySchemaId: "${step_2.dataDeliverySchemaId}"
          pushDeliveryDetailsHttp:
            dataPushUri: "https://rapp.operator.com/callbacks/capacity-monitoring"
        expected_outputs:
          dataJobId: "RETURNED - job identifier"
          status: "ENABLED"

    cleanup:
      - step: 4
        api: "data_access.DELETE_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs/${step_3.dataJobId}"
        method: "DELETE"
        purpose: "Remove data job when monitoring is complete"
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dataJobId: "FROM step_3.dataJobId"
        trigger: "When monitoring objective achieved or cancelled"

    expected_outcome: "Real-time visibility into cell capacity via PUSH_HTTP."
    kpis_involved: ["prb_utilization_dl_pct", "prb_utilization_ul_pct", "active_ues", "throughput_dl_mbps_avg"]
    related_workflows: ["coverage_monitoring_setup", "qos_policy_creation"]

  # -----------------------------------------------------------
  # Historical Data Request (R1AP-Compliant)
  # -----------------------------------------------------------
  historical_data_request:
    id: "wf_003"
    name: "Historical Data Request"
    description: "Request historical KPI data for analysis using R1 Data Management"
    category: "data_management"
    complexity: "medium"
    step_count: 5
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"

    intent_variations:
      - "Get historical RSRP data for cell {cellId} from {startDate} to {endDate}"
      - "I need last week's performance data for {cellId}"
      - "Request historical metrics for analysis"
      - "Download KPI history for trending"
      - "Get me the past month's data for {cellId}"

    context_parameters:
      cellId:
        type: "string"
        examples: ["NRCell-100"]
      startDate:
        type: "datetime"
        examples: ["2024-01-01T00:00:00Z"]
      endDate:
        type: "datetime"
        examples: ["2024-01-31T23:59:59Z"]
      kpis:
        type: "array"
        examples: [["rsrp_dbm", "sinr_db"], ["prb_utilization_dl_pct", "throughput_dl_mbps_avg"]]

    steps:
      # Step 1: Bootstrap - discover endpoints
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path. Must discover dataDiscovery and dataAccess endpoints first."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            dataDiscovery: "/data-discovery/v2"
            dataAccess: "/data-access/v2"

      # Step 2: Discover DME types
      - step: 2
        api: "data_discovery.GET_dme_types"
        uri: "${api_root}${step_1.serviceEndpoints.dataDiscovery}/dme-types"
        method: "GET"
        purpose: "Find available DME types for historical data"
        reasoning: |
          Search for DME types that support ONE_TIME delivery mode and provide
          historical KPI data. Look for types matching the required measurements.
        inputs:
          dataDiscoveryEndpoint: "FROM step_1.serviceEndpoints.dataDiscovery"
        selection_logic: |
          From returned DME types, select one where:
          - dataDeliveryModes includes deliveryMode: ONE_TIME
          - supportedMeasurements matches requested KPIs
        expected_outputs:
          dmeTypeId: "DISCOVERED - e.g., oran:pm-data:1.0.0"
          dataDeliverySchemaId: "DISCOVERED - from response"

      # Step 3: Create one-time data job
      - step: 3
        api: "data_access.POST_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs"
        method: "POST"
        purpose: "Request historical data (one-time delivery)"
        reasoning: |
          Create a ONE_TIME data job for the specified time range.
          Use PUSH_HTTP for delivery - data will be pushed to our callback
          when ready. Include dataAvailabilityNotificationUri if using PULL_HTTP.
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dmeTypeId: "FROM step_2.dmeTypeId"
          dataDeliverySchemaId: "FROM step_2.dataDeliverySchemaId"
          startTime: "FROM context.startDate"
          endTime: "FROM context.endDate"
          cellId: "FROM context.cellId"
          measurementTypes: "FROM context.kpis"
        # R1TD v04.01 compliant request body structure
        # NOTE: R1AP ONE_TIME jobs deliver data via push/pull mechanism,
        # not inline in the create response. Historical date range handling
        # is typically implementation-specific or via job parameters.
        request_body:
          # Use discovered dmeTypeId from step 2 (format: namespace:name:version)
          dmeTypeId: "${step_2.dmeTypeId}"
          # Data production schema per R1TD v04.01 Section 5.1.4.2
          dataJobDefinition:
            # DataSelector (R1TD Table 5.2.2.3.1.1-1)
            dataSelector:
              managementData:
                mgtDataName: "${context.kpis}"
            # TargetSelector (R1TD Table 5.2.2.3.1.2-1)
            targetSelector:
              objectInstances:
                - "/ManagedElement=gNB-001/GNBDUFunction=1/NRCellDU=${context.cellId}"
            # Timing (R1TD Table 5.2.2.3.1.3-1)
            timing:
              collectionWindow:
                startTime: "00:00:00"
                stopTime: "23:59:59"
              granularityPeriod: 900
          dataDeliveryMode: "ONE_TIME"
          dataDeliveryMethod: "PUSH_HTTP"
          # Use discovered dataDeliverySchemaId from step 2
          dataDeliverySchemaId: "${step_2.dataDeliverySchemaId}"
          pushDeliveryDetailsHttp:
            dataPushUri: "https://rapp.operator.com/callbacks/historical-data"
          # Implementation-specific: Historical date range may be passed via
          # job parameters or query params - not standardized in R1AP
          jobParameters:
            historicalStartTime: "${context.startDate}"
            historicalEndTime: "${context.endDate}"
        expected_outputs:
          dataJobId: "RETURNED - job identifier"
          status: "ENABLED"

      # Step 4: Monitor job status
      - step: 4
        api: "data_access.GET_data_job_status"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs/${step_3.dataJobId}/status"
        method: "GET"
        purpose: "Check request status"
        reasoning: "Poll the data job status until completion. Data will be delivered to callback URI when ready."
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dataJobId: "FROM step_3.dataJobId"
        expected_outputs:
          status: "COMPLETED"

    cleanup:
      - step: 5
        api: "data_access.DELETE_data_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.dataAccess}/data-jobs/${step_3.dataJobId}"
        method: "DELETE"
        purpose: "Clean up completed data job"
        inputs:
          dataAccessEndpoint: "FROM step_1.serviceEndpoints.dataAccess"
          dataJobId: "FROM step_3.dataJobId"
        trigger: "After data is received and processed"

    expected_outcome: "Historical KPI data delivered via PUSH_HTTP for offline analysis and trending"
    related_workflows: ["coverage_monitoring_setup", "capacity_monitoring_setup"]

  # -----------------------------------------------------------
  # QoS Policy Creation (R1AP-Compliant)
  # -----------------------------------------------------------
  qos_policy_creation:
    id: "wf_004"
    name: "QoS Policy Creation"
    description: "Create A1 policy for QoS targets using R1 A1 Policy Management"
    category: "a1_policy"
    complexity: "high"
    step_count: 6
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Create QoS policy for enterprise slice with {guaranteedBitRate} Mbps minimum"
      - "Set up quality of service guarantees for slice {sliceId}"
      - "Configure A1 policy for guaranteed throughput"
      - "Create traffic prioritization policy for {cellId}"
      - "I need to guarantee {guaranteedBitRate} Mbps for enterprise users"
      - "Set up QoS targets for network slice"

    context_parameters:
      sliceId:
        type: "object"
        examples:
          - {sst: 1, sd: "000001"}
          - {sst: 2, sd: "000002"}
      guaranteedBitRate:
        type: "integer"
        default: 10000
        examples: [5000, 10000, 50000, 100000]
      packetDelayBudget:
        type: "integer"
        default: 20
        examples: [10, 20, 50, 100]
      cellIds:
        type: "array"
        examples: [["NRCell-100", "NRCell-101"], ["cell-001"]]

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover a1PolicyManagement endpoint."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            a1PolicyManagement: "/a1-policy-management/v1"

      # Step 2: Discover available RICs
      - step: 2
        api: "a1_policy_management.GET_rics"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/rics"
        method: "GET"
        purpose: "Get available Near-RT RICs"
        reasoning: |
          Query available RICs to find one that:
          - Covers the target cells (check managedCells)
          - Supports QoS management capability (check ricCapabilities)
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
        selection_logic: |
          From returned RICs, select one where:
          - managedCells includes all cells from context.cellIds
          - ricCapabilities includes "QOS_MANAGEMENT" or "QOS"
        expected_outputs:
          nearRtRicId: "DISCOVERED - selected RIC ID"
          ricCapabilities: "DISCOVERED - e.g., [QOS_MANAGEMENT, TRAFFIC_STEERING]"

      # Step 3: Discover policy types
      - step: 3
        api: "a1_policy_management.GET_policytypes"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policy-types"
        method: "GET"
        purpose: "Get supported QoS policy types"
        reasoning: |
          Query policy types to find QoS policy schema.
          Look for policyTypeId containing "QoS" or "QosTarget".
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
        selection_logic: |
          From returned policy types, select one where:
          - policyTypeId contains "QoS" or "QosTarget"
          - policySchema supports guaranteedBitRate and packetDelayBudget
        expected_outputs:
          policyTypeId: "DISCOVERED - e.g., ORAN_QoSTarget_1.0.0"
          policySchema: "DISCOVERED - JSON schema for policy body"

      # Step 4: Create the QoS policy
      - step: 4
        api: "a1_policy_management.POST_policies"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies"
        method: "POST"
        purpose: "Create the QoS policy"
        reasoning: |
          Using discovered nearRtRicId and policyTypeId, create the policy.
          The policyObject must conform to the discovered policySchema.
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          nearRtRicId: "FROM step_2.nearRtRicId"
          policyTypeId: "FROM step_3.policyTypeId"
          cellIds: "FROM context.cellIds"
          sliceId: "FROM context.sliceId"
          guaranteedBitRate: "FROM context.guaranteedBitRate"
          packetDelayBudget: "FROM context.packetDelayBudget"
        request_body:
          nearRtRicId: "${step_2.nearRtRicId}"
          policyTypeId: "${step_3.policyTypeId}"
          policyObject:
            scope:
              cellIdList: "${context.cellIds}"
              sliceId: "${context.sliceId}"
            qosObjectives:
              guaranteedBitRate: "${context.guaranteedBitRate}"
              packetDelayBudget: "${context.packetDelayBudget}"
          transient: false
          statusNotificationUri: "https://rapp.operator.com/callbacks/policy-status"
        expected_outputs:
          policyId: "RETURNED - policy identifier"

      # Step 5: Verify policy deployment
      - step: 5
        api: "a1_policy_management.GET_policy_status"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies/${step_4.policyId}/status"
        method: "GET"
        purpose: "Verify policy deployment"
        reasoning: "Confirm the policy was accepted by the Near-RT RIC and is ENFORCED."
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          policyId: "FROM step_4.policyId"
        expected_outputs:
          policyStatus: "ENFORCED"

    cleanup:
      - step: 6
        api: "a1_policy_management.DELETE_policies"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies/${step_4.policyId}"
        method: "DELETE"
        purpose: "Remove policy when no longer needed"
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          policyId: "FROM step_4.policyId"
        trigger: "When policy objective achieved or requirements change"

    expected_outcome: "A1 QoS policy active and enforced by Near-RT RIC, guaranteeing minimum throughput for the slice"
    related_workflows: ["load_balancing_policy", "capacity_monitoring_setup"]

  # -----------------------------------------------------------
  # Load Balancing Policy (R1AP-Compliant)
  # -----------------------------------------------------------
  load_balancing_policy:
    id: "wf_005"
    name: "Load Balancing Policy Creation"
    description: "Create A1 policy for load balancing across cells using R1 A1 Policy Management"
    category: "a1_policy"
    complexity: "high"
    step_count: 6
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"

    intent_variations:
      - "Create load balancing policy for cells {cellIds}"
      - "Distribute traffic across neighbor cells"
      - "Balance load between {cellId} and neighbors"
      - "Set up MLB policy to reduce congestion"
      - "Configure traffic steering for load distribution"

    context_parameters:
      cellIds:
        type: "array"
        examples: [["NRCell-100", "NRCell-101", "NRCell-102"]]
      targetUtilization:
        type: "integer"
        default: 70
        examples: [60, 70, 75]
      hysteresis:
        type: "integer"
        default: 10
        examples: [5, 10, 15]

    steps:
      # Step 1: Bootstrap - discover endpoints
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path. Must discover a1PolicyManagement endpoint first."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            a1PolicyManagement: "/a1-policy-management/v1"

      # Step 2: Discover available RICs
      - step: 2
        api: "a1_policy_management.GET_rics"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/rics"
        method: "GET"
        purpose: "Get available Near-RT RICs"
        reasoning: |
          Query available RICs to find one that:
          - Covers the target cells (check managedCells or coverage area)
          - Supports load balancing capability (check ricCapabilities)
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
        selection_logic: |
          From returned RICs, select one where:
          - managedCells includes all cells from context.cellIds
          - ricCapabilities includes "LOAD_BALANCING" or "MLB"
        expected_outputs:
          nearRtRicId: "DISCOVERED - selected RIC ID"
          ricCapabilities: "DISCOVERED - e.g., [LOAD_BALANCING, TRAFFIC_STEERING]"

      # Step 3: Discover policy types
      - step: 3
        api: "a1_policy_management.GET_policytypes"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policy-types"
        method: "GET"
        purpose: "Get available policy types for load balancing"
        reasoning: |
          Query policy types to find load balancing policy schema.
          Look for policyTypeId containing "LoadBalancing" or "MLB".
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
        selection_logic: |
          From returned policy types, select one where:
          - policyTypeId contains "LoadBalancing" or "MLB"
          - description mentions load balancing or traffic distribution
        expected_outputs:
          policyTypeId: "DISCOVERED - e.g., ORAN_LoadBalancing_1.0.0"
          policySchema: "DISCOVERED - JSON schema for policy body"

      # Step 4: Create policy
      - step: 4
        api: "a1_policy_management.POST_policies"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies"
        method: "POST"
        purpose: "Create the load balancing policy"
        reasoning: |
          Using discovered nearRtRicId and policyTypeId, create the policy.
          The policyObject must conform to the discovered policySchema.
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          nearRtRicId: "FROM step_2.nearRtRicId"
          policyTypeId: "FROM step_3.policyTypeId"
          cellIds: "FROM context.cellIds"
          targetUtilization: "FROM context.targetUtilization"
          hysteresis: "FROM context.hysteresis"
        request_body:
          nearRtRicId: "${step_2.nearRtRicId}"
          policyTypeId: "${step_3.policyTypeId}"
          policyObject:
            scope:
              cellIdList: "${context.cellIds}"
            loadBalancingObjectives:
              targetUtilization: "${context.targetUtilization}"
              hysteresis: "${context.hysteresis}"
              balancingAlgorithm: "PROPORTIONAL"
          transient: false
          statusNotificationUri: "https://rapp.operator.com/callbacks/policy-status"
        expected_outputs:
          policyId: "RETURNED - policy identifier"

      # Step 5: Verify policy status
      - step: 5
        api: "a1_policy_management.GET_policy_status"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies/${step_4.policyId}/status"
        method: "GET"
        purpose: "Verify policy deployment"
        reasoning: "Confirm the policy was accepted by the Near-RT RIC and is ENFORCED."
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          policyId: "FROM step_4.policyId"
        expected_outputs:
          policyStatus: "ENFORCED"

    cleanup:
      - step: 6
        api: "a1_policy_management.DELETE_policies"
        uri: "${api_root}${step_1.serviceEndpoints.a1PolicyManagement}/policies/${step_4.policyId}"
        method: "DELETE"
        purpose: "Remove policy when no longer needed"
        inputs:
          a1PolicyEndpoint: "FROM step_1.serviceEndpoints.a1PolicyManagement"
          policyId: "FROM step_4.policyId"
        trigger: "When load balancing objective achieved"

    expected_outcome: "Load balancing policy active on discovered RIC, distributing traffic across cells to maintain target utilization"
    related_workflows: ["capacity_monitoring_setup", "qos_policy_creation"]

  # -----------------------------------------------------------
  # ML Model Deployment
  # -----------------------------------------------------------
  ml_model_deployment:
    id: "wf_006"
    name: "ML Model Deployment"
    description: "Deploy AI/ML model for inference"
    category: "ai_ml"
    complexity: "high"
    step_count: 5

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Deploy my traffic prediction model to the SMO"
      - "Register and upload my {modelFramework} model"
      - "I need to deploy a {modelName} model for inference"
      - "Set up my ML model for real-time predictions"
      - "Upload and activate my trained model"

    context_parameters:
      modelName:
        type: "string"
        examples: ["TrafficPredictor", "AnomalyDetector", "LoadForecaster"]
      modelVersion:
        type: "string"
        examples: ["1.0.0", "2.0.0"]
      modelFramework:
        type: "string"
        examples: ["PYTORCH", "TENSORFLOW", "ONNX"]
      modelFormat:
        type: "string"
        default: "ONNX"
        examples: ["ONNX", "SAVEDMODEL", "TORCHSCRIPT"]

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover aimlModelManagement endpoint."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            aimlModelManagement: "/r1-aiml/v1"

      # Step 2: Register model
      - step: 2
        api: "aiml_model_registration.POST_mlModels"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlModels"
        method: "POST"
        purpose: "Register the model in the catalog"
        reasoning: "Register the model metadata including name, version, and schemas before uploading artifacts."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelName: "FROM context.modelName"
          modelVersion: "FROM context.modelVersion"
          modelFramework: "FROM context.modelFramework"
          modelFormat: "FROM context.modelFormat"
        request_body:
          modelName: "${context.modelName}"
          modelVersion: "${context.modelVersion}"
          modelFramework: "${context.modelFramework}"
          modelFormat: "${context.modelFormat}"
          inputSchema:
            type: "object"
            description: "Model-specific input schema"
          outputSchema:
            type: "object"
            description: "Model-specific output schema"
        expected_outputs:
          modelId: "RETURNED - model identifier"

      # Step 3: Upload model artifact
      - step: 3
        api: "aiml_model_storage.POST_artifacts"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlModelArtifacts"
        method: "POST"
        purpose: "Upload the model artifact"
        reasoning: "Upload the actual model binary/weights to storage using the modelId from registration."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelId: "FROM step_2.modelId"
          artifactFormat: "FROM context.modelFormat"
        request_body:
          modelId: "${step_2.modelId}"
          artifactName: "${context.modelName}-${context.modelVersion}"
          artifactFormat: "${context.modelFormat}"
        expected_outputs:
          artifactId: "RETURNED - artifact identifier"

      # Step 4: Set up performance monitoring
      - step: 4
        api: "aiml_performance_monitoring.POST_subscriptions"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlPerformanceSubscriptions"
        method: "POST"
        purpose: "Set up performance monitoring"
        reasoning: "Configure monitoring to track model accuracy and latency after deployment."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelId: "FROM step_2.modelId"
        request_body:
          modelId: "${step_2.modelId}"
          performanceMetrics: ["accuracy", "latency", "inferenceCount", "errorRate"]
          notificationUri: "https://rapp.operator.com/callbacks/ml-performance"
        expected_outputs:
          subscriptionId: "RETURNED - subscription identifier"

      # Step 5: Verify inference readiness
      - step: 5
        api: "aiml_model_inference.GET_capabilities"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlInferenceCapabilities"
        method: "GET"
        purpose: "Verify inference readiness"
        reasoning: "Confirm the model is available for inference by checking capabilities."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
        expected_outputs:
          inferenceCapabilities: "RETURNED - available inference modes"

    expected_outcome: "ML model deployed, stored, and ready for inference with performance monitoring active"
    related_workflows: ["ml_model_training", "ml_inference_request"]

  # -----------------------------------------------------------
  # ML Model Training
  # -----------------------------------------------------------
  ml_model_training:
    id: "wf_007"
    name: "ML Model Training"
    description: "Train or retrain ML model with new data"
    category: "ai_ml"
    complexity: "high"
    step_count: 5

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Train my model with the new dataset"
      - "Retrain {modelName} with updated parameters"
      - "Start training job for model {modelId}"
      - "I need to improve my model accuracy"
      - "Run training with {epochs} epochs"

    context_parameters:
      modelId:
        type: "string"
        examples: ["model-001"]
      trainingDataUri:
        type: "string"
        examples: ["http://data-lake.example.com/datasets/traffic-data-v2"]
      hyperparameters:
        type: "object"
        examples:
          - {learningRate: 0.001, batchSize: 32, epochs: 100}
          - {learningRate: 0.0001, batchSize: 64, epochs: 200}

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover aimlModelManagement endpoint."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            aimlModelManagement: "/r1-aiml/v1"

      # Step 2: Check training capabilities
      - step: 2
        api: "aiml_training_capability.GET_capabilities"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlTrainingCapabilities"
        method: "GET"
        purpose: "Check available training resources"
        reasoning: "Verify that training infrastructure is available and determine supported configurations."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
        expected_outputs:
          trainingCapabilities: "RETURNED - available training configurations"

      # Step 3: Start training job
      - step: 3
        api: "aiml_model_training.POST_training_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlTrainingJobs"
        method: "POST"
        purpose: "Start training job"
        reasoning: "Create and start the training job with specified hyperparameters for the existing model."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelId: "FROM context.modelId"
          trainingDataUri: "FROM context.trainingDataUri"
          hyperparameters: "FROM context.hyperparameters"
        request_body:
          modelId: "${context.modelId}"
          trainingDataUri: "${context.trainingDataUri}"
          hyperparameters: "${context.hyperparameters}"
          statusNotificationUri: "https://rapp.operator.com/callbacks/training-status"
        expected_outputs:
          trainingJobId: "RETURNED - training job identifier"

      # Step 4: Monitor training progress
      - step: 4
        api: "aiml_model_training.GET_training_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlTrainingJobs/${step_3.trainingJobId}"
        method: "GET"
        purpose: "Monitor training progress"
        reasoning: "Check training status until completion. Poll periodically or wait for notification."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          trainingJobId: "FROM step_3.trainingJobId"
        expected_outputs:
          status: "COMPLETED"
          metrics: "RETURNED - e.g., {loss: 0.05, accuracy: 0.95}"

      # Step 5: Store trained model artifact
      - step: 5
        api: "aiml_model_storage.POST_artifacts"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlModelArtifacts"
        method: "POST"
        purpose: "Store trained model"
        reasoning: "Save the newly trained model artifact for future inference."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelId: "FROM context.modelId"
          trainingJobId: "FROM step_3.trainingJobId"
        request_body:
          modelId: "${context.modelId}"
          artifactName: "${context.modelId}-trained"
          sourceTrainingJobId: "${step_3.trainingJobId}"
        expected_outputs:
          artifactId: "RETURNED - artifact identifier"

    expected_outcome: "Model training completed with improved accuracy, new artifact stored"

  # -----------------------------------------------------------
  # rApp Onboarding
  # -----------------------------------------------------------
  rapp_onboarding:
    id: "wf_008"
    name: "rApp Onboarding"
    description: "Complete rApp registration and API publishing"
    category: "rapp_management"
    complexity: "medium"
    step_count: 4

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Onboard my rApp to the SMO"
      - "Register rApp {rAppName} with vendor {vendor}"
      - "Deploy and register my application"
      - "I need to onboard a new rApp"
      - "Set up my rApp in the SMO"

    context_parameters:
      rAppName:
        type: "string"
        examples: ["rApp-TrafficOptimizer", "rApp-AnomalyDetector"]
      vendor:
        type: "string"
        examples: ["Nokia", "Ericsson", "Viavi", "Custom"]
      rAppType:
        type: "string"
        examples: ["SERVICE_PRODUCER", "SERVICE_CONSUMER", "HYBRID"]

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover rappManagement and capifPublish endpoints."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            rappManagement: "/r1-rapp-management/v1"
            capifPublish: "/capif-publish/v1"

      # Step 2: Register the rApp
      - step: 2
        api: "rapp_registration.POST_rapps"
        uri: "${api_root}${step_1.serviceEndpoints.rappManagement}/rapps"
        method: "POST"
        purpose: "Register the rApp"
        reasoning: "Register rApp metadata including vendor, type, and requirements with the SMO."
        inputs:
          rappEndpoint: "FROM step_1.serviceEndpoints.rappManagement"
          rAppName: "FROM context.rAppName"
          vendor: "FROM context.vendor"
          rAppType: "FROM context.rAppType"
        request_body:
          rAppName: "${context.rAppName}"
          vendor: "${context.vendor}"
          rAppType: "${context.rAppType}"
          description: "rApp for ${context.rAppName} operations"
        expected_outputs:
          rAppId: "RETURNED - rApp identifier"

      # Step 3: Publish rApp service APIs
      - step: 3
        api: "service_registration.POST_service_apis"
        uri: "${api_root}${step_1.serviceEndpoints.capifPublish}/${step_2.rAppId}/service-apis"
        method: "POST"
        purpose: "Publish rApp service APIs"
        reasoning: "Make rApp's APIs discoverable by other applications through CAPIF."
        inputs:
          capifEndpoint: "FROM step_1.serviceEndpoints.capifPublish"
          rAppId: "FROM step_2.rAppId"
        request_body:
          apiName: "${context.rAppName}-api"
          apiVersion: "1.0.0"
          description: "Service APIs for ${context.rAppName}"
        expected_outputs:
          serviceApiId: "RETURNED - service API identifier"

      # Step 4: Verify registration status
      - step: 4
        api: "rapp_registration.GET_rapp_status"
        uri: "${api_root}${step_1.serviceEndpoints.rappManagement}/rapps/${step_2.rAppId}/status"
        method: "GET"
        purpose: "Verify registration status"
        reasoning: "Confirm rApp is successfully registered and operational."
        inputs:
          rappEndpoint: "FROM step_1.serviceEndpoints.rappManagement"
          rAppId: "FROM step_2.rAppId"
        expected_outputs:
          status: "ACTIVE"

    expected_outcome: "rApp registered, APIs published, and operational in the SMO"

  # -----------------------------------------------------------
  # NOTE: O1 and O2 Workflows Removed
  # -----------------------------------------------------------
  # The following workflows have been REMOVED as they use O1/O2 APIs:
  #   - alarm_investigation (O1: fault_management)
  #   - configuration_update (O1: configuration_management)
  #   - performance_analysis (O1: performance_management)
  #   - ocloud_resource_query (O2: o2_infrastructure_management)
  #   - nf_deployment (O2: o2_deployment_management)
  #
  # For O1 workflows, see: o1_workflows.yaml (if needed)
  # For O2 workflows, see: o2_workflows.yaml (if needed)
  # -----------------------------------------------------------

  # -----------------------------------------------------------
  # EI Data Subscription (R1AP-Compliant)
  # -----------------------------------------------------------
  ei_data_subscription:
    id: "wf_009"
    name: "Enrichment Information Subscription"
    description: "Subscribe to A1 enrichment information data using R1 A1-EI APIs"
    category: "a1_services"
    complexity: "medium"
    step_count: 4
    includes_cleanup: true

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Subscribe to UE location data"
      - "Get enrichment information for {eiTypeId}"
      - "I need EI data for my rApp"
      - "Set up enrichment data subscription"
      - "Get real-time UE context information"

    context_parameters:
      eiTypeId:
        type: "string"
        examples: ["ue-location-data", "ue-trajectory-data"]

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover a1EnrichmentInformation endpoint."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            a1EnrichmentInformation: "/r1-a1-ei/v1"

      # Step 2: Discover EI types
      - step: 2
        api: "a1_enrichment_information.GET_eitypes"
        uri: "${api_root}${step_1.serviceEndpoints.a1EnrichmentInformation}/eitypes"
        method: "GET"
        purpose: "Discover EI types"
        reasoning: "Find available enrichment information types to subscribe to."
        inputs:
          a1EiEndpoint: "FROM step_1.serviceEndpoints.a1EnrichmentInformation"
        selection_logic: |
          From returned EI types, select one where:
          - eiTypeId matches requested type (e.g., ue-location-data)
          - OR description indicates UE context/location data
        expected_outputs:
          eiTypeId: "DISCOVERED - e.g., ue-location-data"
          eiJobParametersSchema: "DISCOVERED - JSON schema for EI job"

      # Step 3: Create EI job
      - step: 3
        api: "a1_enrichment_information.POST_eijobs"
        uri: "${api_root}${step_1.serviceEndpoints.a1EnrichmentInformation}/eijobs"
        method: "POST"
        purpose: "Create EI job"
        reasoning: "Subscribe to enrichment information stream using discovered eiTypeId."
        inputs:
          a1EiEndpoint: "FROM step_1.serviceEndpoints.a1EnrichmentInformation"
          eiTypeId: "FROM step_2.eiTypeId"
        request_body:
          eiTypeId: "${step_2.eiTypeId}"
          jobDefinition:
            ueIdList: ["imsi-310150123456789"]
          targetUri: "https://rapp.operator.com/callbacks/ei-data"
        expected_outputs:
          eiJobId: "RETURNED - EI job identifier"
          status: "RUNNING"

    cleanup:
      - step: 4
        api: "a1_enrichment_information.DELETE_eijobs"
        uri: "${api_root}${step_1.serviceEndpoints.a1EnrichmentInformation}/eijobs/${step_3.eiJobId}"
        method: "DELETE"
        purpose: "Remove EI job when no longer needed"
        inputs:
          a1EiEndpoint: "FROM step_1.serviceEndpoints.a1EnrichmentInformation"
          eiJobId: "FROM step_3.eiJobId"
        trigger: "When enrichment data no longer required"

    expected_outcome: "Enrichment information subscription active, receiving UE context data via callback"
    related_workflows: ["coverage_monitoring_setup", "qos_policy_creation"]

  # -----------------------------------------------------------
  # ML Inference Request (R1AP-Compliant)
  # -----------------------------------------------------------
  ml_inference_request:
    id: "wf_010"
    name: "ML Inference Request"
    description: "Request prediction from deployed ML model using R1 AI/ML APIs"
    category: "ai_ml"
    complexity: "easy"
    step_count: 3

    # IMPORTANT: Agent starts knowing ONLY:
    #   api_root = "https://smo.example.com"
    #   bootstrap_path = "/bootstrap/v1/bootstrap-info"
    # Everything else must be discovered dynamically.

    intent_variations:
      - "Get prediction from {modelName}"
      - "Run inference on my data"
      - "Use the traffic model to predict load"
      - "What does the model predict for this input?"
      - "Request real-time prediction"

    context_parameters:
      modelName:
        type: "string"
        examples: ["TrafficPredictor"]
      inputData:
        type: "object"
        examples:
          - {ueMetrics: [1.2, 3.4, 5.6], cellMetrics: {prbUtilization: 75, activeUsers: 150}}

    steps:
      # Step 1: Bootstrap - ALWAYS the first step
      - step: 1
        api: "bootstrap.GET_bootstrap_info"
        uri: "${api_root}/bootstrap/v1/bootstrap-info"
        method: "GET"
        purpose: "Discover available R1 service endpoints"
        reasoning: "Agent only knows api_root and bootstrap path at startup. Must call bootstrap first to discover aimlModelManagement endpoint."
        inputs:
          api_root: "FROM agent_config.api_root"
        expected_outputs:
          serviceEndpoints:
            aimlModelManagement: "/r1-aiml/v1"

      # Step 2: Find the model
      - step: 2
        api: "aiml_model_discovery.GET_mlModels"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlModels"
        method: "GET"
        purpose: "Find the model"
        reasoning: "Search for the model by name to get its modelId."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelName: "FROM context.modelName"
        query_params:
          modelName: "${context.modelName}"
        selection_logic: |
          From returned models, select one where:
          - modelName matches context.modelName
          - status is READY or DEPLOYED
        expected_outputs:
          modelId: "DISCOVERED - model identifier"

      # Step 3: Request inference
      - step: 3
        api: "aiml_model_inference.POST_inference_jobs"
        uri: "${api_root}${step_1.serviceEndpoints.aimlModelManagement}/mlInferenceJobs"
        method: "POST"
        purpose: "Request inference"
        reasoning: "Submit input data for prediction using the discovered modelId."
        inputs:
          aimlEndpoint: "FROM step_1.serviceEndpoints.aimlModelManagement"
          modelId: "FROM step_2.modelId"
          inputData: "FROM context.inputData"
        request_body:
          modelId: "${step_2.modelId}"
          inputData: "${context.inputData}"
          inferenceMode: "SYNC"
          timeout: 5000
        expected_outputs:
          inferenceJobId: "RETURNED - inference job identifier"
          prediction: "RETURNED - e.g., {predictedLoad: 85.5}"

    expected_outcome: "Prediction returned from ML model"
    related_workflows: ["ml_model_deployment", "capacity_monitoring_setup"]

# ============================================================
# WORKFLOW COMBINATIONS - Complex multi-workflow scenarios
# ============================================================
workflow_combinations:
  diagnose_and_remediate_congestion:
    name: "Diagnose and Remediate Cell Congestion"
    description: "End-to-end workflow from diagnosis to policy deployment"
    workflows_in_sequence:
      - capacity_monitoring_setup
      - load_balancing_policy
    trigger_condition: "prb_utilization_dl_pct > 85"

  predictive_optimization:
    name: "Predictive Network Optimization"
    description: "Use ML prediction to proactively deploy policies"
    workflows_in_sequence:
      - ml_inference_request
      - load_balancing_policy
    trigger_condition: "predicted_load > 80"

  complete_rapp_deployment:
    name: "Complete rApp Deployment with ML"
    description: "Full rApp onboarding with ML model deployment"
    workflows_in_sequence:
      - rapp_onboarding
      - ml_model_deployment
      - coverage_monitoring_setup
